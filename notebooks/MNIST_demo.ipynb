{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\") # so we can import the layer_sim library\n",
    "\n",
    "from layer_sim import networks\n",
    "from layer_sim import datasets\n",
    "from layer_sim.train import train_net, test_net\n",
    "from layer_sim.pruning.IMP import imp_lrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and NN preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batch = 128\n",
    "test_batch = 128\n",
    "trainloader, testloader = datasets.MNIST(\"../data\", train_batch, test_batch, num_workers=4)\n",
    "net = networks.LeNet5(num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: insert image of LeNet5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_init = 0.1\n",
    "weight_decay = 0.0001\n",
    "momentum = 0.9\n",
    "epochs = 15\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_annealing_rate = 10\n",
    "lr_annealing_schedule = [10, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr_init, momentum=momentum, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "===> Epoch 1/15 ### Loss 0.3291197659830252 ### Performance 0.8938\n===> Epoch 2/15 ### Loss 0.06732262536038955 ### Performance 0.9794166666666667\n===> Epoch 3/15 ### Loss 0.04838982847606142 ### Performance 0.9854\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9b19ab56af7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtr_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_perf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_annealing_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr_annealing_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs_annealing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr_annealing_schedule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\mzullich\\Documents\\sim_layer_pub\\layer_sim\\train.py\u001b[0m in \u001b[0;36mtrain_net\u001b[1;34m(net, epochs, criterion, optimizer, trainloader, device, performance, epochs_annealing, lr_annealing_factor, resume_checkpoint, save_checkpoint, mask, sequential)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;31m# gradient clipping to avoid explosion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mparam_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"fro\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;34mr\"\"\"See :func:`torch.norm`\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_infos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[0;32m    674\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrobenius_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"nuc\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"fro\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tr_loss, tr_perf = train_net(net, epochs, criterion, optimizer, trainloader, device=device, lr_annealing_factor=lr_annealing_rate, epochs_annealing=lr_annealing_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "===> TEST ### Loss 2.3029794692993164 ### Performance 0.0972\n"
    }
   ],
   "source": [
    "te_loss, te_perf = test_net(net, testloader, criterion, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: save the NN\n",
    "\n",
    "In the next cell we save the state_dict along with a number of auxiliary data (train/test loss/performance) in a dictionary called `save_dict`. We save this dict in a `save_root` which we will use also as a base for the IMP checkpoints.\n",
    "\n",
    "The `save_dict` mimics the structure of IMP's checkpoint (minus the pruning mask, which is absent in the case of the complete model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'tr_loss' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3f0f28922355>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m save_dict = {\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;34m\"train_loss\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtr_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;34m\"train_perf\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtr_perf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;34m\"test_loss\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mte_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;34m\"test_perf\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mte_perf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tr_loss' is not defined"
     ]
    }
   ],
   "source": [
    "save_dict = {\n",
    "    \"train_loss\": tr_loss,\n",
    "    \"train_perf\": tr_perf,\n",
    "    \"test_loss\": te_loss,\n",
    "    \"test_perf\": te_perf,\n",
    "    \"parameters\": net.state_dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_root = \"../models/LeNet5\"\n",
    "save_name = \"complete_net.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'save_dict' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ad5b9a8af0c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'save_dict' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(save_dict, os.path.join(save_root, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# load the NN\n",
    "net.load_state_dict(torch.load(os.path.join(save_root, save_name))[\"parameters\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store complete model's representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataloader for representation w/ Train set as False\n",
    "reprloader, _ = datasets.MNIST(\"../data\", 128, train=False, num_workers=4)\n",
    "compl = net.forward_with_hooks() # TODO: limit datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMP application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip: we can help ourselves with `net.state_dict().keys()` to enucleate the layers names which we'll be pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "odict_keys(['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.2.weight', 'classifier.2.bias', 'classifier.4.weight', 'classifier.4.bias'])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "net.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we wish to prune all of the weights & biases of the conv layers + the f-c layers minus the last one.\n",
    "The selection is operated on the keys of the state_dict compared using regex:\n",
    "\n",
    "* we can use a generic `\"features\"` pattern to catch all of the conv layers\n",
    "* we use a more specific regex `\"classifier\\.[02]\\.\"` to catch the first 2 f-c layers (but not the last one which has ID `4` in the state_dict keys)\n",
    "\n",
    "Note: if we had BatchNorm layers in `features`, we should be more careful in indicating the layers to prune, similarly to what we did in `classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_to_prune = [\"features\", r\"classifier\\.[02]\\.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=====> Iteration of IMP: 1/2\nProportion of parameters in mask 0.5095664700850853\n===> Epoch 1/15 ### Loss 0.01041195536716841 ### Performance 0.99655\n===> Epoch 2/15 ### Loss 0.012068730958690866 ### Performance 0.9958833333333333\n===> Epoch 3/15 ### Loss 0.008705891965283081 ### Performance 0.9970666666666667\n===> Epoch 4/15 ### Loss 0.011660329529092026 ### Performance 0.9962833333333333\n===> Epoch 5/15 ### Loss 0.008792778549799308 ### Performance 0.99715\n===> Epoch 6/15 ### Loss 0.00852779282204962 ### Performance 0.99725\n===> Epoch 7/15 ### Loss 0.009600953032627391 ### Performance 0.9970666666666667\n===> Epoch 8/15 ### Loss 0.010967730930063408 ### Performance 0.9962666666666666\n===> Epoch 9/15 ### Loss 0.00826772124649336 ### Performance 0.9974666666666666\n===> Epoch 10/15 ### Loss 0.006784967440033021 ### Performance 0.9976666666666667\n===> Epoch 11/15 ### Loss 0.007287115667760372 ### Performance 0.9976\n===> Epoch 12/15 ### Loss 0.007883973504335154 ### Performance 0.9973666666666666\n===> Epoch 13/15 ### Loss 0.007422720286358769 ### Performance 0.9976333333333334\n===> Epoch 14/15 ### Loss 0.006379599401067632 ### Performance 0.99805\n===> Epoch 15/15 ### Loss 0.008467702254427908 ### Performance 0.99715\n===> TEST ### Loss 0.038090113550424576 ### Performance 0.9905\n==> Checkpoint for iteration 0 dumped to ../models/LeNet5/IMP\\IMP_checkpoint_0.torch\n=====> Iteration of IMP: 2/2\nProportion of parameters in mask 0.26434970512762795\n===> Epoch 1/15 ### Loss 0.009504154830922684 ### Performance 0.9971333333333333\n===> Epoch 2/15 ### Loss 0.004882070575693312 ### Performance 0.9984\n===> Epoch 3/15 ### Loss 0.0047669949031279735 ### Performance 0.9986666666666667\n===> Epoch 4/15 ### Loss 0.0025643149473976033 ### Performance 0.99925\n===> Epoch 5/15 ### Loss 0.002024161127244588 ### Performance 0.9995\n===> Epoch 6/15 ### Loss 0.003912443902925588 ### Performance 0.9988333333333334\n===> Epoch 7/15 ### Loss 0.004013679017367152 ### Performance 0.9986833333333334\n===> Epoch 8/15 ### Loss 0.0054457217921425275 ### Performance 0.9983\n===> Epoch 9/15 ### Loss 0.006435201655669759 ### Performance 0.9977833333333334\n===> Epoch 10/15 ### Loss 0.006669257620551313 ### Performance 0.9978166666666667\n===> Epoch 11/15 ### Loss 0.006428229098720476 ### Performance 0.9979333333333333\n===> Epoch 12/15 ### Loss 0.0051740847983475155 ### Performance 0.99825\n===> Epoch 13/15 ### Loss 0.0064204560870459925 ### Performance 0.9978\n===> Epoch 14/15 ### Loss 0.0038005587624230733 ### Performance 0.9988833333333333\n===> Epoch 15/15 ### Loss 0.007003315165669968 ### Performance 0.9976833333333334\n===> TEST ### Loss 0.036352138966321945 ### Performance 0.9895\n==> Checkpoint for iteration 1 dumped to ../models/LeNet5/IMP\\IMP_checkpoint_1.torch\n"
    }
   ],
   "source": [
    "imp_iterations = 2\n",
    "save_path=\"../models/LeNet5/IMP\" # checkpoints will be saved in this folder as IMP_checkpoint_n.pt, where `n` is the iteration number\n",
    "pruning_rate = 0.5\n",
    "imp_lrr(net, epochs, criterion, optimizer, trainloader, imp_iterations, device=device, testloader=testloader, save_path=save_path, layer_ids_to_prune=layers_to_prune, pruning_factor=pruning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1593613202783",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}