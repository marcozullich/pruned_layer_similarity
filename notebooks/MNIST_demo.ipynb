{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: this notebook is merely an example of usage of the `layer_sim` library and doesn't focus on the performance of the provided NNs nor on the accurate analysis of the resulting similarities.\n",
    "The code provided is run on MNIST so that everyone may reproduce the results in a small enough amount of time on a medium-sized machine without a CUDA-capable GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"..\") # so we can import the layer_sim library\n",
    "\n",
    "from layer_sim import networks\n",
    "from layer_sim import datasets\n",
    "from layer_sim import nn_comparison\n",
    "from layer_sim import preprocessing\n",
    "from layer_sim.train import train_net, test_net\n",
    "from layer_sim.pruning.IMP import imp_lrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and NN preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batch = 128\n",
    "test_batch = 128\n",
    "trainloader, testloader = datasets.MNIST(\"../data\", train_batch, test_batch, num_workers=4)\n",
    "net = networks.LeNet5(num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: insert image of LeNet5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_init = 0.1\n",
    "weight_decay = 0.0001\n",
    "momentum = 0.9\n",
    "epochs = 15\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_annealing_rate = 10\n",
    "lr_annealing_schedule = [10, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr_init, momentum=momentum, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "===> Epoch 1/15 ### Loss 0.3238158259967963 ### Performance 0.8953333333333333\n===> Epoch 2/15 ### Loss 0.06931836195240418 ### Performance 0.9788333333333333\n===> Epoch 3/15 ### Loss 0.04757271823982398 ### Performance 0.9855833333333334\n===> Epoch 4/15 ### Loss 0.04082236483022571 ### Performance 0.9876833333333334\n===> Epoch 5/15 ### Loss 0.032276718960702416 ### Performance 0.9903\n===> Epoch 6/15 ### Loss 0.028784222680702805 ### Performance 0.9910666666666667\n===> Epoch 7/15 ### Loss 0.02341511012427509 ### Performance 0.9927666666666667\n===> Epoch 8/15 ### Loss 0.024698692759002248 ### Performance 0.9923833333333333\n===> Epoch 9/15 ### Loss 0.023087299082769703 ### Performance 0.9929666666666667\n===> Epoch 10/15 ### Loss 0.020946485105218987 ### Performance 0.9932166666666666\n===> Epoch 11/15 ### Loss 0.016838115830874693 ### Performance 0.9945833333333334\nLR annealed: previous 0.1, current 0.01\n===> Epoch 12/15 ### Loss 0.007709789935398536 ### Performance 0.9976\n===> Epoch 13/15 ### Loss 0.004453768027938592 ### Performance 0.99885\nLR annealed: previous 0.01, current 0.001\n===> Epoch 14/15 ### Loss 0.0035638416282987844 ### Performance 0.99915\n===> Epoch 15/15 ### Loss 0.003456470188164773 ### Performance 0.9992166666666666\n"
    }
   ],
   "source": [
    "tr_loss, tr_perf = train_net(net, epochs, criterion, optimizer, trainloader, device=device, lr_annealing_factor=lr_annealing_rate, epochs_annealing=lr_annealing_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "===> TEST ### Loss 0.02399575710296631 ### Performance 0.9939\n"
    }
   ],
   "source": [
    "te_loss, te_perf = test_net(net, testloader, criterion, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: save the NN\n",
    "\n",
    "In the next cell we save the state_dict along with a number of auxiliary data (train/test loss/performance) in a dictionary called `save_dict`. We save this dict in a `save_root` which we will use also as a base for the IMP checkpoints.\n",
    "\n",
    "The `save_dict` mimics the structure of IMP's checkpoint (minus the pruning mask, which is absent in the case of the complete model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict = {\n",
    "    \"train_loss\": tr_loss,\n",
    "    \"train_perf\": tr_perf,\n",
    "    \"test_loss\": te_loss,\n",
    "    \"test_perf\": te_perf,\n",
    "    \"parameters\": net.state_dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_root = \"../models/LeNet5\"\n",
    "save_name = \"complete_net.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(save_dict, os.path.join(save_root, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# load the NN\n",
    "net.load_state_dict(torch.load(os.path.join(save_root, save_name))[\"parameters\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store complete model's representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataloader for representation w/ Train set as False\n",
    "reprloader, _ = datasets.MNIST(\"../data\", 128, train=False, num_workers=4)\n",
    "datapoints_repr = 500\n",
    "layers_to_hook = (torch.nn.ReLU, torch.nn.AvgPool2d)\n",
    "compl_repr = net.extract_network_representation(reprloader, limit_datapoints=datapoints_repr, layer_types_to_hook=layers_to_hook, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMP application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip: we can help ourselves with `net.state_dict().keys()` to enucleate the layers names which we'll be pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "odict_keys(['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.2.weight', 'classifier.2.bias', 'classifier.4.weight', 'classifier.4.bias'])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "net.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we wish to prune all of the weights & biases of the conv layers + the f-c layers minus the last one.\n",
    "The selection is operated on the keys of the state_dict compared using regex:\n",
    "\n",
    "* we can use a generic `\"features\"` pattern to catch all of the conv layers\n",
    "* we use a more specific regex `\"classifier\\.[02]\\.\"` to catch the first 2 f-c layers (but not the last one which has ID `4` in the state_dict keys)\n",
    "\n",
    "Note: if we had BatchNorm layers in `features`, we should be more careful in indicating the layers to prune, similarly to what we did in `classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_to_prune = [\"features\", r\"classifier\\.[02]\\.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=====> Iteration of IMP: 1/2\nProportion of parameters in mask 0.5095664700850853\n===> Epoch 1/15 ### Loss 0.003976711449120194 ### Performance 0.9991\n===> Epoch 2/15 ### Loss 0.003863610198131452 ### Performance 0.99915\n===> Epoch 3/15 ### Loss 0.003786710744607262 ### Performance 0.99915\n===> Epoch 4/15 ### Loss 0.0037242088944806407 ### Performance 0.9991833333333333\n===> Epoch 5/15 ### Loss 0.003669509372898998 ### Performance 0.9991833333333333\n===> Epoch 6/15 ### Loss 0.003616517808668626 ### Performance 0.9992\n===> Epoch 7/15 ### Loss 0.0035696580502282207 ### Performance 0.9992333333333333\n===> Epoch 8/15 ### Loss 0.003518850996547068 ### Performance 0.9992333333333333\n===> Epoch 9/15 ### Loss 0.0034778801025201877 ### Performance 0.9992\n===> Epoch 10/15 ### Loss 0.0034353855072132623 ### Performance 0.99925\n===> Epoch 11/15 ### Loss 0.0033997997631668112 ### Performance 0.9993\n===> Epoch 12/15 ### Loss 0.003360308953448354 ### Performance 0.9992833333333333\n===> Epoch 13/15 ### Loss 0.003325033530585157 ### Performance 0.9992833333333333\n===> Epoch 14/15 ### Loss 0.003291446531022666 ### Performance 0.9993\n===> Epoch 15/15 ### Loss 0.0032537219382085215 ### Performance 0.9993166666666666\n===> TEST ### Loss 0.024466587230563164 ### Performance 0.9934\n==> Checkpoint for iteration 0 dumped to ../models/LeNet5/IMP\\IMP_checkpoint_0.pt\n=====> Iteration of IMP: 2/2\nProportion of parameters in mask 0.26434970512762795\n===> Epoch 1/15 ### Loss 0.00815364953825871 ### Performance 0.9978833333333333\n===> Epoch 2/15 ### Loss 0.00698656011056155 ### Performance 0.9980833333333333\n===> Epoch 3/15 ### Loss 0.0066313786981627345 ### Performance 0.99825\n===> Epoch 4/15 ### Loss 0.006413392267562449 ### Performance 0.9982666666666666\n===> Epoch 5/15 ### Loss 0.006234715721112055 ### Performance 0.9983333333333333\n===> Epoch 6/15 ### Loss 0.006084167186294993 ### Performance 0.9984\n===> Epoch 7/15 ### Loss 0.005943073315359652 ### Performance 0.9984166666666666\n===> Epoch 8/15 ### Loss 0.00581679322066096 ### Performance 0.9984833333333333\n===> Epoch 9/15 ### Loss 0.005705105085950345 ### Performance 0.9985\n===> Epoch 10/15 ### Loss 0.005602733031815538 ### Performance 0.9985833333333334\n===> Epoch 11/15 ### Loss 0.0055055749492409324 ### Performance 0.9985833333333334\n===> Epoch 12/15 ### Loss 0.0054179491339872285 ### Performance 0.9986333333333334\n===> Epoch 13/15 ### Loss 0.005332575820805505 ### Performance 0.9986333333333334\n===> Epoch 14/15 ### Loss 0.005254665355244652 ### Performance 0.9986666666666667\n===> Epoch 15/15 ### Loss 0.005176951340027153 ### Performance 0.9986666666666667\n===> TEST ### Loss 0.023320063948631287 ### Performance 0.9928\n==> Checkpoint for iteration 1 dumped to ../models/LeNet5/IMP\\IMP_checkpoint_1.pt\n"
    }
   ],
   "source": [
    "imp_iterations = 2\n",
    "save_path=\"../models/LeNet5/IMP\" # checkpoints will be saved in this folder as IMP_checkpoint_n.pt, where `n` is the iteration number\n",
    "pruning_rate = 0.5\n",
    "imp_lrr(net, epochs, criterion, optimizer, trainloader, imp_iterations, device=device, testloader=testloader, save_path=save_path, layer_ids_to_prune=layers_to_prune, pruning_factor=pruning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: it is also possible to resume IMP execution from a given checkpoint -- we will soon provide the code to do that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract pruned network representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = \"IMP_checkpoint_{}.pt\"\n",
    "load_file = os.path.join(save_path, file_pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_repr = []\n",
    "for i in range(imp_iterations):\n",
    "    net.load_state_dict(torch.load(load_file.format(i))[\"parameters \"])\n",
    "    pruned_repr.append(net.extract_network_representation(reprloader, limit_datapoints=datapoints_repr, layer_types_to_hook=layers_to_hook, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SVCCA\n",
    "SVCCA_ROOT = \"../../svcca\"\n",
    "sys.path.append(os.path.expanduser(SVCCA_ROOT))\n",
    "from cca_core import get_cca_similarity\n",
    "\n",
    "# prepare lambda fct to get scalar for mean_cca_similarity\n",
    "mean_cca_sim = lambda x,y: get_cca_similarity(x,y)[\"mean\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get kernels of representations (for CKA & NBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fct to get linear kernels\n",
    "# linear kernel is just M M^T, where M is a matrix whose rows are datapoints and columns are the neurons\n",
    "def get_linear_kernel(matrix):\n",
    "    # if matrix is more than two-dimensional, flatten the last dimensions into a single one\n",
    "    if len(matrix.shape) == 4:\n",
    "        matrix_2d = preprocessing.reshape_4d_tensor(matrix)\n",
    "        return matrix_2d @ matrix_2d.T\n",
    "    return matrix @ matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_compl = [get_linear_kernel(r) for r in compl_repr]\n",
    "kerels_pruned = []\n",
    "for rep in pruned_repr:\n",
    "    kerels_pruned.append([get_linear_kernel(r) for r in rep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline_cca(tensor, var_kept = .99):\n",
    "    if len(tensor.shape) == 4:\n",
    "        tensor = preprocessing.reshape_4d_tensor(tensor, True)\n",
    "    tensor = preprocessing.svd_reduction(tensor, var_kept)\n",
    "    return tensor.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "compl_repr = [preprocess_pipeline_cca(r) for r in compl_repr]\n",
    "for j in range(len(pruned_repr)):\n",
    "    pruned_repr[j] = [preprocess_pipeline_cca(r) for r in pruned_repr[j]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "adding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\nadding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\nadding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\nadding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\nadding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\nadding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\nadding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\nadding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\nadding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\nadding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\nadding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\nadding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\nadding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\nadding eps to diagonal and taking inverse\ntaking square root\ndot products...\ntrying to take final svd\ncomputed everything!\n"
    }
   ],
   "source": [
    "# store measurements in tensor whose dimensions are: metric, iteration, layer\n",
    "similarities = torch.zeros([2, imp_iterations, len(compl_repr)])\n",
    "\n",
    "for i in range(imp_iterations):\n",
    "    for l, (compl, pruned) in enumerate(zip(compl_repr, pruned_repr[i])):\n",
    "        similarities[0, i, l] = mean_cca_sim(compl.detach().numpy(), pruned.detach().numpy())\n",
    "    for l, (compl, pruned) in enumerate(zip(kernels_compl, kerels_pruned[i])):\n",
    "        similarities[1, i, l] = nn_comparison.cka(compl.detach(), pruned.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[0.9997, 0.9998, 0.9985, 0.9990, 0.9888, 0.9858, 0.9992],\n         [0.9980, 0.9985, 0.9889, 0.9914, 0.9331, 0.9302, 0.9944]],\n\n        [[0.4692, 0.3582, 0.7535, 0.6547, 0.8563, 0.7598, 0.9681],\n         [0.4725, 0.3637, 0.7509, 0.6518, 0.8333, 0.7490, 0.9577]]])"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "similarities"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1593706732852",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}